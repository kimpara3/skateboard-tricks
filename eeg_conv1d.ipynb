{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75389811-cbfa-4454-8d28-ffa0f440ba91",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551cf447-6e07-44bf-af7b-5fc2e3c3e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from torchinfo import summary\n",
    "\n",
    "from eeg_utils import *\n",
    "from eeg_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a431484-3ea0-47e8-a8fa-06b95ce5a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,target=prepare_all()\n",
    "\n",
    "left_channels=[0, 2, 4, 6, 8, 10, 12, 14, 20, 22, 24, 26, 28, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 64, 66, 68, 70]\n",
    "right_channels=[1, 3, 5, 7, 9, 11, 13, 15, 21, 23, 25, 27, 29, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 65, 67, 69, 71]\n",
    "other_channels=[i for i in range(72) if i not in left_channels and i not in right_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe954ec-6894-4442-9f7a-f2adf6aad36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_std(data):\n",
    "    std = data.std(axis=1) # (N,C)\n",
    "    std[std==0]=1.0\n",
    "    stdmed = np.median(std,axis=0) # (C,)\n",
    "    std = np.array([np.clip(std[:,c],stdmed[c],np.inf) for c in range(72)])\n",
    "    std = std.T\n",
    "    normalized = data/std[:,None,:]\n",
    "\n",
    "    # 左右差\n",
    "    left=normalized[:,:,left_channels].copy()\n",
    "    right=normalized[:,:,right_channels].copy()\n",
    "    normalized[:,:,left_channels] = left-right\n",
    "    normalized[:,:,right_channels] = left+right\n",
    "    \n",
    "    std = normalized.std(axis=1)\n",
    "    std[std==0]=1.0\n",
    "    stdmed = np.median(std,axis=0) # (C,)\n",
    "    std = np.array([np.clip(std[:,c],stdmed[c],np.inf) for c in range(72)])\n",
    "    std = std.T\n",
    "    normalized = normalized/(2*std[:,None,:])\n",
    "    return normalized\n",
    "\n",
    "def make_train_data(sub, train_index,val_index):\n",
    "    normalized_data=[]\n",
    "    for i in range(3):\n",
    "        # 左右差\n",
    "        data = train_data[sub][i].copy()\n",
    "        normalized = rl_std(data)\n",
    "        normalized = np.clip(normalized, -3,3)\n",
    "\n",
    "        normalized_data.append(normalized)\n",
    "        \n",
    "    X_train = np.concatenate([normalized_data[i] for i in train_index])[:,:,:72] # +/-50ms\n",
    "    y_train = np.concatenate([target[sub][i] for i in train_index])\n",
    "\n",
    "    X_val = normalized_data[val_index[0]][:,25:275,:72].copy()\n",
    "    y_val = target[sub][val_index[0]]\n",
    "          \n",
    "    return X_train,X_val,y_train,y_val\n",
    "\n",
    "\n",
    "def make_test_data(sub):\n",
    "    data = test_data[sub].copy()\n",
    "    normalized = rl_std(data)\n",
    "    normalized = np.clip(normalized, -3,3)\n",
    "\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0a235-9cc5-492c-b37b-433780f6c39f",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3eca6ca-bcc3-47a4-be0d-cf67e9fec18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(pred_dict,sub,isplit,save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    filename = os.path.join(save_path, f\"{sub}_{isplit}.json\")\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(pred_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d35c8b3-a013-4843-a3bd-02b6132173d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/500], Loss: 0.0041, Val Loss: 0.2728, Acc: 0.905\n",
      "loss 0.22065124028845678\n",
      "acc 0.9177215189873418\n",
      "Epoch [500/500], Loss: 0.0035, Val Loss: 0.4229, Acc: 0.856\n",
      "loss 0.31453006267547606\n",
      "acc 0.8875\n",
      "Epoch [500/500], Loss: 0.0071, Val Loss: 0.4720, Acc: 0.830\n",
      "loss 0.3747638966302452\n",
      "acc 0.8364779874213837\n",
      "Epoch [500/500], Loss: 0.0058, Val Loss: 0.7153, Acc: 0.806\n",
      "loss 0.4784692764282227\n",
      "acc 0.81875\n",
      "Epoch [500/500], Loss: 0.0079, Val Loss: 0.3940, Acc: 0.863\n",
      "loss 0.3565009593963623\n",
      "acc 0.85625\n",
      "Epoch [500/500], Loss: 0.0045, Val Loss: 0.4052, Acc: 0.881\n",
      "loss 0.3328737222923423\n",
      "acc 0.8742138364779874\n",
      "Epoch [500/500], Loss: 0.0076, Val Loss: 0.6136, Acc: 0.794\n",
      "loss 0.4050909519195557\n",
      "acc 0.85625\n",
      "Epoch [500/500], Loss: 0.0044, Val Loss: 0.5140, Acc: 0.830\n",
      "loss 0.3615709460756314\n",
      "acc 0.8805031446540881\n",
      "Epoch [500/500], Loss: 0.0086, Val Loss: 0.5734, Acc: 0.823\n",
      "loss 0.38253861439378956\n",
      "acc 0.879746835443038\n",
      "Epoch [500/500], Loss: 0.0030, Val Loss: 0.3736, Acc: 0.875\n",
      "loss 0.3065016508102417\n",
      "acc 0.90625\n",
      "Epoch [500/500], Loss: 0.0025, Val Loss: 0.2343, Acc: 0.925\n",
      "loss 0.1629597544670105\n",
      "acc 0.93125\n",
      "Epoch [500/500], Loss: 0.0019, Val Loss: 0.4163, Acc: 0.887\n",
      "loss 0.3511946678161621\n",
      "acc 0.9\n",
      "Epoch [500/500], Loss: 0.0082, Val Loss: 0.5002, Acc: 0.836\n",
      "loss 0.3762052763932906\n",
      "acc 0.8553459119496856\n",
      "Epoch [500/500], Loss: 0.0072, Val Loss: 0.2420, Acc: 0.893\n",
      "loss 0.21072274933821\n",
      "acc 0.9245283018867925\n",
      "Epoch [500/500], Loss: 0.0055, Val Loss: 0.4776, Acc: 0.844\n",
      "loss 0.39518420696258544\n",
      "acc 0.85\n"
     ]
    }
   ],
   "source": [
    "weights={}\n",
    "for sub in train_data.keys():\n",
    "    weights[sub]=[]\n",
    "    cv=3\n",
    "    kf=KFold(cv)\n",
    "    for isplit, (train_index, val_index) in enumerate(kf.split(train_data[sub])):\n",
    "        X_train,X_val,y_train,y_val=make_train_data(sub, train_index, val_index)\n",
    "\n",
    "        param=dict(\n",
    "            num_epochs=500,\n",
    "            num_classes=3,\n",
    "            lr=2e-6,\n",
    "            weight_decay=1e-0,\n",
    "            batch_size=16,\n",
    "            dropout=0.0,\n",
    "            conv_params=[\n",
    "                dict(out_channels=2048, kernel_size=5, stride=2),\n",
    "                dict(out_channels=512, kernel_size=3, stride=1),\n",
    "            ],\n",
    "            seed=1,\n",
    "        )\n",
    "        est=SignalEstimator(**param)\n",
    "        model_summary=summary(model=est.model, input_size=(1,250,72))\n",
    "        train_loss,val_loss=est.fit(X_train,y_train,val_X=X_val,val_y=y_val,verbose=0)\n",
    "        weights[sub].append(est.model.state_dict())\n",
    "\n",
    "        predictions = est(X_val)\n",
    "        predictions_dict={f\"{sub}-{isplit}\":predictions.tolist()}\n",
    "        save_prediction(predictions_dict,sub,isplit,\"conv1d_val\")\n",
    "                                    \n",
    "        print(\"loss\",est.minimum_loss)\n",
    "        print(\"acc\",est.score(X_val, y_val%10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b674b9-a3b5-4d11-a16e-40961826909f",
   "metadata": {},
   "source": [
    "# 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a467599-d901-428c-a5c5-c47e70a5813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=prepare_testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f715f88-f1a0-4a3e-9ff2-28fb6e9b9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in train_data.keys():\n",
    "    for isplit,weight in enumerate(weights[sub]):\n",
    "        param=dict(\n",
    "            num_epochs=500,\n",
    "            num_classes=3,\n",
    "            lr=2e-6,\n",
    "            weight_decay=1e-0,\n",
    "            batch_size=16,\n",
    "            dropout=0.0,\n",
    "            conv_params=[\n",
    "                dict(out_channels=2048, kernel_size=5, stride=2),\n",
    "                dict(out_channels=512, kernel_size=3, stride=1),\n",
    "            ],\n",
    "            seed=1,\n",
    "        )\n",
    "        est=SignalEstimator(**param)\n",
    "        est.minimum_loss_weight=weight\n",
    "\n",
    "        X_test=make_test_data(sub)\n",
    "        predictions = est(X_test)\n",
    "        predictions_dict={f\"{sub}-{isplit}\":predictions.tolist()}\n",
    "        save_prediction(predictions_dict,sub,isplit,\"conv1d_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da6060-8edf-4ec9-838f-5dcc6af51731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
