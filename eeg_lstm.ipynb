{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75389811-cbfa-4454-8d28-ffa0f440ba91",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551cf447-6e07-44bf-af7b-5fc2e3c3e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from torchinfo import summary\n",
    "\n",
    "from eeg_utils import *\n",
    "from eeg_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a431484-3ea0-47e8-a8fa-06b95ce5a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,target=prepare_all()\n",
    "\n",
    "left_channels=[0, 2, 4, 6, 8, 10, 12, 14, 20, 22, 24, 26, 28, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 64, 66, 68, 70]\n",
    "right_channels=[1, 3, 5, 7, 9, 11, 13, 15, 21, 23, 25, 27, 29, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 65, 67, 69, 71]\n",
    "other_channels=[i for i in range(72) if i not in left_channels and i not in right_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe954ec-6894-4442-9f7a-f2adf6aad36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(sub, train_index,val_index):\n",
    "    normalized_data=[]\n",
    "    for i in range(3):\n",
    "        # 左右差\n",
    "        data = train_data[sub][i].copy()\n",
    "        \n",
    "        left=data[:,:,left_channels].copy()\n",
    "        right=data[:,:,right_channels].copy()\n",
    "        data[:,:,left_channels] = left-right\n",
    "        data[:,:,right_channels] = left+right\n",
    "\n",
    "        std = data.std(axis=(0,1),keepdims=True)\n",
    "        std[std==0]=1.0\n",
    "        normalized = data/std\n",
    "        normalized = np.clip(normalized, -4,4)\n",
    "        normalized_data.append(normalized)\n",
    "        \n",
    "    X_train = np.concatenate([normalized_data[i] for i in train_index])[:,:,:72] # +/-50ms\n",
    "    y_train = np.concatenate([target[sub][i] for i in train_index])\n",
    "\n",
    "    X_val = normalized_data[val_index[0]][:,25:275,:72].copy()\n",
    "    y_val = target[sub][val_index[0]]\n",
    "          \n",
    "    return X_train,X_val,y_train,y_val\n",
    "\n",
    "\n",
    "def make_test_data(sub):\n",
    "    X_test = test_data[sub][:,:,:72].copy()\n",
    "\n",
    "    # 左右差\n",
    "    left=X_test[:,:,left_channels].copy()\n",
    "    right=X_test[:,:,right_channels].copy()\n",
    "    X_test[:,:,left_channels] = left-right\n",
    "    X_test[:,:,right_channels] = left+right\n",
    "    \n",
    "    std = X_test.std(axis=(0,1),keepdims=True)\n",
    "    std[std==0]=1\n",
    "    X_test = X_test / std\n",
    "    X_test = np.clip(X_test, -4,4)\n",
    "\n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0a235-9cc5-492c-b37b-433780f6c39f",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3eca6ca-bcc3-47a4-be0d-cf67e9fec18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(pred_dict,sub,isplit,save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    filename = os.path.join(save_path, f\"{sub}_{isplit}.json\")\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(pred_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d35c8b3-a013-4843-a3bd-02b6132173d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.3179, Val Loss: 1.4003, Acc: 0.563\n",
      "loss 0.6891713202754154\n",
      "acc 0.6582278481012658\n",
      "Epoch [50/50], Loss: 0.3543, Val Loss: 0.6714, Acc: 0.731\n",
      "loss 0.5152502536773682\n",
      "acc 0.725\n",
      "Epoch [50/50], Loss: 0.3146, Val Loss: 0.5981, Acc: 0.761\n",
      "loss 0.5094840091729315\n",
      "acc 0.7295597484276729\n",
      "Epoch [50/50], Loss: 0.1964, Val Loss: 0.6531, Acc: 0.781\n",
      "loss 0.517423677444458\n",
      "acc 0.7\n",
      "Epoch [50/50], Loss: 0.0916, Val Loss: 0.5583, Acc: 0.844\n",
      "loss 0.5583277225494385\n",
      "acc 0.84375\n",
      "Epoch [50/50], Loss: 0.3462, Val Loss: 0.7298, Acc: 0.711\n",
      "loss 0.5817463233036065\n",
      "acc 0.7169811320754716\n",
      "Epoch [50/50], Loss: 0.0222, Val Loss: 1.2884, Acc: 0.669\n",
      "loss 0.7336989402770996\n",
      "acc 0.675\n",
      "Epoch [50/50], Loss: 0.0355, Val Loss: 0.8152, Acc: 0.805\n",
      "loss 0.4693814643523978\n",
      "acc 0.8364779874213837\n",
      "Epoch [50/50], Loss: 0.0331, Val Loss: 1.1672, Acc: 0.728\n",
      "loss 0.667559949657585\n",
      "acc 0.7278481012658228\n",
      "Epoch [50/50], Loss: 0.0303, Val Loss: 1.0109, Acc: 0.762\n",
      "loss 0.33721065521240234\n",
      "acc 0.89375\n",
      "Epoch [50/50], Loss: 0.0059, Val Loss: 0.5774, Acc: 0.881\n",
      "loss 0.4240878582000732\n",
      "acc 0.8875\n",
      "Epoch [50/50], Loss: 0.0047, Val Loss: 0.6565, Acc: 0.869\n",
      "loss 0.3888855934143066\n",
      "acc 0.8625\n",
      "Epoch [50/50], Loss: 0.1504, Val Loss: 1.0073, Acc: 0.736\n",
      "loss 0.729403129913522\n",
      "acc 0.6352201257861635\n",
      "Epoch [50/50], Loss: 0.1187, Val Loss: 0.6386, Acc: 0.811\n",
      "loss 0.43832814918374113\n",
      "acc 0.8427672955974843\n",
      "Epoch [50/50], Loss: 0.1132, Val Loss: 1.0689, Acc: 0.719\n",
      "loss 0.692770528793335\n",
      "acc 0.64375\n"
     ]
    }
   ],
   "source": [
    "weights={}\n",
    "for sub in train_data.keys():\n",
    "    weights[sub]=[]\n",
    "    cv=3\n",
    "    kf=KFold(cv)\n",
    "    for isplit, (train_index, val_index) in enumerate(kf.split(train_data[sub])):\n",
    "        X_train,X_val,y_train,y_val=make_train_data(sub, train_index, val_index)\n",
    "\n",
    "        param=dict(\n",
    "            num_epochs=50,\n",
    "            num_classes=3,\n",
    "            lr=3e-5,\n",
    "            weight_decay=1e-3,\n",
    "            batch_size=16,\n",
    "            dropout=0.0,\n",
    "            conv_params=[\n",
    "                dict(out_channels=128, kernel_size=5, stride=2),\n",
    "            ],\n",
    "            lstm_param=dict(\n",
    "                hidden_size=256,\n",
    "                num_layers=6,\n",
    "            ),\n",
    "            seed=1,\n",
    "        )\n",
    "        est=SignalEstimator(**param)\n",
    "        model_summary=summary(model=est.model, input_size=(1,250,72))\n",
    "        train_loss,val_loss=est.fit(X_train,y_train,val_X=X_val,val_y=y_val,verbose=0)\n",
    "        weights[sub].append(est.model.state_dict())\n",
    "\n",
    "        predictions = est(X_val)\n",
    "        predictions_dict={f\"{sub}-{isplit}\":predictions.tolist()}\n",
    "        save_prediction(predictions_dict,sub,isplit,\"lstm_val\")\n",
    "                                    \n",
    "        print(\"loss\",est.minimum_loss)\n",
    "        print(\"acc\",est.score(X_val, y_val%10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b674b9-a3b5-4d11-a16e-40961826909f",
   "metadata": {},
   "source": [
    "# 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a467599-d901-428c-a5c5-c47e70a5813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=prepare_testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f715f88-f1a0-4a3e-9ff2-28fb6e9b9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in train_data.keys():\n",
    "    for isplit,weight in enumerate(weights[sub]):\n",
    "        param=dict(\n",
    "            num_epochs=50,\n",
    "            num_classes=3,\n",
    "            lr=3e-5,\n",
    "            weight_decay=1e-3,\n",
    "            batch_size=16,\n",
    "            dropout=0.0,\n",
    "            conv_params=[\n",
    "                dict(out_channels=128, kernel_size=5, stride=2),\n",
    "            ],\n",
    "            lstm_param=dict(\n",
    "                hidden_size=256,\n",
    "                num_layers=6,\n",
    "            ),\n",
    "            seed=1,\n",
    "        )\n",
    "        est=SignalEstimator(**param)\n",
    "        est.minimum_loss_weight=weight\n",
    "\n",
    "        X_test=make_test_data(sub)\n",
    "        predictions = est(X_test)\n",
    "        predictions_dict={f\"{sub}-{isplit}\":predictions.tolist()}\n",
    "        save_prediction(predictions_dict,sub,isplit,\"lstm_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da6060-8edf-4ec9-838f-5dcc6af51731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
